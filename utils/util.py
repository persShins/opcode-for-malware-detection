import json
import torch
import pandas as pd
from pathlib import Path
from itertools import repeat
from collections import OrderedDict
from omegaconf import OmegaConf
from typing import Union


def ensure_dir(dirname):
    dirname = Path(dirname)
    if not dirname.is_dir():
        dirname.mkdir(parents=True, exist_ok=False)

def read_conf(fpath) -> Union[dict, OrderedDict]:
    fpath = Path(fpath)
    if fpath.suffix == '.yaml':
        cfgfile = OmegaConf.load(fpath)
        return OmegaConf.to_container(cfgfile, resolve=True)
    else:
        with fpath.open('rt') as f:
            return json.load(f, object_hook=OrderedDict)

def write_conf(config, fpath):
    fpath = Path(fpath)
    if fpath.suffix == '.yaml':
        OmegaConf.save(config, fpath)
    else:
        with fpath.open('wt') as f:
            json.dump(config, f, indent=4, sort_keys=False)

def inf_loop(data_loader):
    ''' wrapper function for endless data loader. '''
    for loader in repeat(data_loader):
        yield from loader

def prepare_device(n_gpu_use):
    """ GPU가 디바이스에 있을 시 설정합니다.  """
    
    n_gpu = torch.cuda.device_count()
    if n_gpu_use > 0 and n_gpu == 0:
        print("GPU가 확인되지 않습니다. 학습 모델에 CPU를 사용합니다.")

        n_gpu_use = 0
    if n_gpu_use > n_gpu:
        print(f"사용하고자 하는 GPU의 개수가 설정한 값보다 작습니다. {n_gpu}개만 사용할 수 있습니다.")

        n_gpu_use = n_gpu
    device = torch.device('cuda:0' if n_gpu_use > 0 else 'cpu')
    list_ids = list(range(n_gpu_use))
    return device, list_ids

class MetricTracker(object):
    def __init__(self, *keys, writer=None):
        self.writer = writer
        self._data = pd.DataFrame(index=keys, columns=['total', 'counts', 'average'])
        self.reset()

    def reset(self):
        for col in self._data.columns:
            self._data[col].values[:] = 0

    def update(self, key, value, n=1, is_metric=False, epoch=None):
        if self.writer is not None:
            if is_metric is True:
                self.writer.log_metric(key, value, step=epoch)
            else:
                self.writer.log_param(key, value)
        self._data.total[key] += value * n
        self._data.counts[key] += n
        self._data.average[key] = self._data.total[key] / self._data.counts[key]

    def avg(self, key):
        return self._data.average[key]

    def result(self):
        return dict(self._data.average)
