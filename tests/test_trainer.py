import pytest
import torch
import shutil
import data_loader.data_loaders as module_data
import model.model as module_arch
import model.metric as module_metric
import model.loss as module_loss
from utils import read_conf, prepare_device
from trainer import SklearnTrainer
from parse_config import ConfigParser
from pathlib import Path
from trainer import Trainer

class TestMalwareDetectionTrainer:
    def test_sklearn_trainer(self, setup_logger):
        self.remove_existed_folder()
        config = self.create_config('sklearn')
        logger = setup_logger
        
        data_loader = config.init_obj('data_loader', module_data, 
                                logger=logger, save_dir='tests/passage')
        dataset = data_loader.dataset.embed_passage
        
        model = config.init_obj('arch', module_arch)
        logger.info(model)
        
        metrics = [getattr(module_metric, met) for met in config['metrics']]
        
        trainer = SklearnTrainer(
            model=model,
            metric_ftns=metrics,
            config=config,
            dataset=dataset
        )
        
        trainer.train()
        
    def test_torch_trainer(self, setup_logger):
        self.remove_existed_folder()
        config = self.create_config('torch')
        logger = setup_logger
        data_loader = config.init_obj('data_loader', module_data, 
                                logger=logger, save_dir='tests/passage')
        valid_data_loader = data_loader.split_validation()
        device, device_ids = prepare_device(config['n_gpu'])
        
        in_features = data_loader.dataset.embed_passage['embed_passage'].shape[-1]
        model = config.init_obj('arch', module_arch, in_features)
        logger.info(model)
        
        model = model.to(device)
        if len(device_ids) > 1:
            model = torch.nn.DataParallel(model, device_ids=device_ids)
            
        criterion = getattr(module_loss, config['loss'])
        metrics = [getattr(module_metric, met) for met in config['metrics']]
        
        trainable_params = filter(lambda p: p.requires_grad, model.parameters())
        optimizer = config.init_obj('optimizer', torch.optim, trainable_params)
        lr_scheduler = config.init_obj('lr_scheduler', torch.optim.lr_scheduler, optimizer)
        
        trainer = Trainer(
            model=model,
            criterion=criterion,
            metric_ftns=metrics,
            optimizer=optimizer,
            config=config,
            device=device,
            data_loader=data_loader,
            valid_data_loader=valid_data_loader,
            lr_scheduler=lr_scheduler
        )
        trainer.train()
    
    @staticmethod
    def create_config(framework='sklearn'):
        conf_fpath = f'tests/{framework}_config.yaml'
        config = read_conf(conf_fpath)
        config = ConfigParser(config=config)
        return config
        
    @staticmethod
    def remove_existed_folder():
        def remove_folder(dpath):
            if dpath.exists():
                shutil.rmtree(dpath)
        
        test_path = Path('tests')
        mlflow_dir = test_path / 'mlflow'
        remove_folder(mlflow_dir)
            
        passage_dir = test_path / 'passage'
        remove_folder(passage_dir)
            
        model_dir = test_path / 'models'
        remove_folder(model_dir)